{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import docker \n",
    "import tarfile"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "client = docker.from_env()\n",
    "device_request = [docker.types.DeviceRequest(count=-2, capabilities=[['gpu']])]\n",
    "container = client.containers.run(\"3850639cdf7a\", detach=True, stdin_open=True, tty=True, mem_limit=\"1500m\", device_requests=device_request)\n",
    "print(\"Container started\")\n",
    "\n",
    "tar = tarfile.open('ClientInput.tar', mode='w')\n",
    "try:\n",
    "    tar.add(\"ModelCode\"+\".py\")\n",
    "    tar.add(\"ModelTrainer.py\")\n",
    "finally:\n",
    "    tar.close()\n",
    "data = open('ClientInput.tar', 'rb').read()\n",
    "container.put_archive('/workspace', data)\n",
    "print(\"Model sent\")\n",
    "\n",
    "exit_code, output = container.exec_run(\"python \" + \"ModelTrainer.py\")\n",
    "print(output.decode())\n",
    "\n",
    "f = open('ClientOutput.tar', 'wb')\n",
    "bits, stat = container.get_archive('/workspace/model.pb')\n",
    "print(stat)\n",
    "for chunk in bits:\n",
    "    f.write(chunk)\n",
    "f.close()\n",
    "\n",
    "container.stop()\n",
    "container.remove()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Container started\n",
      "Model sent\n",
      "9913344it [00:01, 5599165.74it/s]                             \n",
      "29696it [00:00, 18416982.34it/s]         \n",
      "1649664it [00:00, 5369604.89it/s]                             \n",
      "5120it [00:00, 9882575.46it/s]          \n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448224956/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448224956/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "cuda\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "\n",
      "{'name': 'model.pb', 'size': 119511, 'mode': 420, 'mtime': '2021-09-17T09:21:11.352557171+05:30', 'linkTarget': ''}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data\n",
    "from ModelCode import CNN\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "BATCH_SIZE = 1000\n",
    "\n",
    "train_data = datasets.MNIST(root = 'data', train = True, transform = ToTensor(), download = True)\n",
    "train_iterator = data.DataLoader(train_data, shuffle = True, batch_size = BATCH_SIZE)\n",
    "\n",
    "test_data = datasets.MNIST(root = 'data', train = False, transform = ToTensor())\n",
    "test_iterator = data.DataLoader(test_data, batch_size = BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def train(model, iterator, optimizer, criterion): \n",
    "    epoch_loss = 0\n",
    "    model.train()                \n",
    "    for (x, y) in iterator:   \n",
    "        x, y = x.to(device), y.to(device)        \n",
    "        optimizer.zero_grad()                \n",
    "        y_pred = model(x) \n",
    "        loss = criterion(y_pred, y)         \n",
    "        loss.backward()              \n",
    "        optimizer.step()                     \n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss/len(iterator)         \n",
    "\n",
    "def evaluate(model, iterator, criterion):      \n",
    "    epoch_loss = 0\n",
    "    model.eval()                                 \n",
    "    with torch.no_grad():                        \n",
    "        for (x, y) in iterator:  \n",
    "            x, y = x.to(device), y.to(device)          \n",
    "            y_pred = model(x)           \n",
    "            loss = criterion(y_pred, y)      \n",
    "            epoch_loss += loss.item()\n",
    "        return epoch_loss/len(iterator) \n",
    "\n",
    "def pred(model, iterator):   \n",
    "    correct = 0\n",
    "    model.eval()                                 \n",
    "    with torch.no_grad():                        \n",
    "        for (x, y) in iterator: \n",
    "            x, y = x.to(device), y.to(device)          \n",
    "            y_pred = model(x)\n",
    "            y_pred = np.argmax(y_pred.cpu().detach().numpy(), axis=1)\n",
    "            y = y.cpu().detach().numpy() \n",
    "            for i in range(len(y_pred)):\n",
    "                if y_pred[i] == y[i]:\n",
    "                    correct += 1\n",
    "    return correct"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from ModelCode import CNN\n",
    "my_tar = tarfile.open('ClientOutput.tar')\n",
    "my_tar.extract('model.pb')\n",
    "my_tar.close()\n",
    "t1 = torch.load(\"model.pb\")\n",
    "print(t1)\n",
    "t1.to(device) \n",
    "print(\"Model loaded on GPU\")\n",
    "print(\"Test accuracy :\",pred(t1, test_iterator)/(BATCH_SIZE*len(test_iterator)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n",
      "Model loaded on GPU\n",
      "Test accuracy : 0.9756\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}